2024-12-14 10:47:40,766 - __main__ - INFO - Initialized Hugging Face Inference Client with model: meta-llama/Llama-3.2-1B
2024-12-14 10:47:40,768 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.126.13:5000
2024-12-14 10:47:40,768 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-14 10:48:29,802 - __main__ - INFO - User input:  gender male, Senior_Citizen no, Is_Married yes, Dependents yes, tenure 10, Dual yes, Contract month-to-month, Paperless_Billing yes, Payment_Method electronic check, Monthly_Charges 100, Online_Security yes, Online_Backup yes, Device_Protection no, Streaming_TV yes, Streaming_Movies no, Internet_Service yes, Tech_Support yes
2024-12-14 10:48:29,819 - __main__ - INFO - Input successfully parsed and converted to dataframe.
2024-12-14 10:48:29,878 - __main__ - INFO - Predicted churn probability: 0.1769958736004606
2024-12-14 10:48:29,879 - __main__ - INFO - Generated prompt: you are a helpful assistant that help the marketing team predict churn probability
        for customers. you are the best chatbot assistant in the world.output the churn equals Low Risk and output the probability equals 0.1769958736004606
2024-12-14 10:48:45,135 - __main__ - INFO - LLM response: 

    """
def get_churn_probability(customer):
    
    # calculate customer's risk score 
    if (customer['age'] >50) or (customer['income']>100000):  
        
        return "High"
            
    elif ((customer["gender"] == 'F') & (customer["education_level"]=="Bachelor")): 
        
            return "Medium"   
         
    else:
         return "Low"


2024-12-14 10:48:45,137 - werkzeug - INFO - 192.168.126.25 - - [14/Dec/2024 10:48:45] "POST /api/v1/response HTTP/1.1" 200 -
